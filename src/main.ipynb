{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from pkgs.kitti_utils import *\n",
    "from pkgs.kitti_detection_utils import *\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from sklearn import linear_model\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset \n",
    "DATA_PATH = r'./../dataset/2011_10_03_drive_0047_sync'\n",
    "\n",
    "#image path\n",
    "image_paths = sorted(glob(os.path.join(DATA_PATH, 'image_02/data/*.png')))\n",
    "#lidar path\n",
    "lid_paths = sorted(glob(os.path.join(DATA_PATH, 'velodyne_points/data/*.bin')))\n",
    "#GPS/IMU path\n",
    "imu_paths = sorted(glob(os.path.join(DATA_PATH, r'oxts/data**/*.txt')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_calib_file = './../dataset/2011_10_03_calib/calib_cam_to_cam.txt'\n",
    "def cam_transformation(filepath):\n",
    "    with open(filepath,'r') as f:\n",
    "        calib = f.readlines()\n",
    "\n",
    "    # get projection matrices (rectified left camera --> left camera (u,v,z))\n",
    "    P_rect2_cam2 = np.array([float(x) for x in calib[25].strip().split(' ')[1:]]).reshape((3,4))\n",
    "\n",
    "    # get rectified rotation matrices (left camera --> rectified left camera)\n",
    "    R_ref0_rect2 = np.array([float(x) for x in calib[24].strip().split(' ')[1:]]).reshape((3, 3,))\n",
    "\n",
    "    # add (0,0,0) translation and convert to homogeneous coordinates\n",
    "    R_ref0_rect2 = np.insert(R_ref0_rect2, 3, values=[0,0,0], axis=0)\n",
    "    R_ref0_rect2 = np.insert(R_ref0_rect2, 3, values=[0,0,0,1], axis=1)\n",
    "\n",
    "\n",
    "    # get rigid transformation from Camera 0 (ref) to Camera 2\n",
    "    R_2 = np.array([float(x) for x in calib[21].strip().split(' ')[1:]]).reshape((3,3))\n",
    "    t_2 = np.array([float(x) for x in calib[22].strip().split(' ')[1:]]).reshape((3,1))\n",
    "\n",
    "    # get cam0 to cam2 rigid body transformation in homogeneous coordinates\n",
    "    T_ref0_ref2 = np.insert(np.hstack((R_2, t_2)), 3, values=[0,0,0,1], axis=0)\n",
    "    \n",
    "    return P_rect2_cam2, R_ref0_rect2, T_ref0_ref2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_rect2_cam2,R_ref0_rect2,T_ref0_ref2 = cam_transformation(cam_calib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lid_transformation(filepath):\n",
    "\n",
    "    T_velo_ref0 = get_rigid_transformation(filepath)\n",
    "    return T_velo_ref0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lid_calib_file = './../dataset/2011_10_03_calib/calib_velo_to_cam.txt'\n",
    "T_velo_ref0 = lid_transformation(lid_calib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imu_transformation(filepath):\n",
    "\n",
    "    T_imu_velo = get_rigid_transformation(filepath)\n",
    "    return T_imu_velo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_calib_file = './../dataset/2011_10_03_calib/calib_imu_to_velo.txt'\n",
    "T_imu_velo = imu_transformation(imu_calib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detetction model\n",
    "def detection_model(weights,classes):\n",
    "    model = YOLO()\n",
    "    model.classes = classes \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = \"yolov8n.pt\"\n",
    "classes = [0, 1, 2, 3, 5, 7] # person, bicycle, car, motorcycle, bus, truck\n",
    "model = detection_model(weights,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
